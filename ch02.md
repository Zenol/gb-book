The CPU core
============

Now, you can load a game into memory, but once the gamme is in the memory,
nothing happen. You need to emulate the heart of the Game Boy:
the GPU.
This section is devoted to structuring and writing the CPU core,
the part of the emulater responsible for fetching instructions,
and reproducing the behavior of a single instructions on our memory.

The CPU core is, without a doubt, the place the more
<<propice>> to bugs. CPU cores are hard to debbug and
often made of a big bunch of code (easily more than 1 000 lines).
If you don't feel confortable with developping one, you can
allow yourself to reuse an existing one from a known emulator.
If you want to write yours -- because it's an <<enrichissante>>
experience, and you'll probably learn a lot -- allow yourself to look at
other implementations.
Also, remember you don't need a fully functionnal CPU core to
emulate a specific game. For example, tetris require only a restricted set of
instructions, and their execution don't have to be perfectly faithfull.

States and Registers
--------------------

The execution of a program is basically repeating three
actions : fetching instructions from memory into the CPU core,
decoding the instructions -- 
associating to a binary number a block of code --
and finaly runing the associated block of code.

![The fetch-decode-execute cycle](images/cpu-core.png)

Those three operations, called the instruction cycle,
are repeated indefinitely until
the `STOP` instruction is executed, or the
power is cut.

Between two instruction cycles,
what change is the internal states of the CPU.
The CPU have a small set of variables, called registers,
that are modified by executing instructions.
Some registers are directly accessibles, and others
are modified thanks to specific instructions.

Our first step in writing a CPU core is then
defining the structure that is going to contain all this states.
We need the registers bits register a, b, c, d, e, h, l and f,
the stack pointer and the program counter.

``` {.rust}
#[derive(PartialEq, Eq, Default, Debug)]
struct Cpu {
    // CPU's registers
	a : u8,
	b : u8,
	c : u8,
	d : u8,
	e : u8,
	h : u8,
	l : u8,
	f : u8,

    // Program counter
    pc : u16,
    // Stack pointer
    sp : u16,
}
```

Since instruction will have to acess both memory and the CPU,
it is easier to give them both through a structure repraisenting
a _virtual machine_.

```
#[derive(PartialEq, Eq, Default, Debug)]
struct Vm {
    cpu : Cpu,
    mmu : Mmu,
}
```

Design of the CPU core
----------------------

The center of the CPU core is the dispatch loop.
This loop fetch the next instruction from the memory located
at the address stored by the __programme counter__,
look for the associated block of code to execute, and then
count the amount of time enlapsed.

First, we need two functions for reading byte
at the address pointed by the __programme counter__,
and incrementing the counter.

``` {.rust}
/// Read a byte from the memory pointed by PC, and increment PC
fn read_program_byte(vm : &mut Vm) -> u8 {
    let byte = mmu::rb(vm.cpu.pc, &mut vm.mmu);
    vm.cpu.pc += 1;
    return byte;
}

/// Read a word (2bytes) from the memory pointed by PC, and increment PC
fn read_program_word(vm : &mut Vm) -> u16 {
    let word = mmu::rw(vm.cpu.pc, &mut vm.mmu);
    vm.cpu.pc += 2;
    return word;
}
```

Notice that in rust, the `+ 1` operator can create an integer
overflow.
An integer overflow is what happen when the variable already
contains the maximum number it can, and you want to add some positive
value to it.
If you compile in debug mode, a such overflow will cause
a crash of your application with an error message.
But if you compile in release mode,
the overflow occuring in the previous lines
will just reset the variable back to `0`, which
is the behavior expected from the processor.

Now, we can write the dispatch loop:
``` {.rust}
// The dispatch loop
while true {
    execute_one_instruction(vm);
}

// Execute exactly one instruction by the CPU
//
// The function load the byte pointed by PC, increment PC,
// and call dispatch with the opcode to run the instruction.
// It returns the time this instruction would have taken on
// the real hardware.
fn execute_one_instruction(vm : &mut Vm) -> Clock {
    // Disable bios once executed
    if vm.cpu.pc >= 0x100 {
        vm.mmu.bios_enabled = false;
    }

    // Fetch the instruction
    let opcode = read_program_byte(vm);

    // Run opcode
    let clock = dispatch(opcode)(vm);

    return clock;
}
```

The `dispatch`  function is actually particuliar.
It get an opcode -- a binary number describing the instruction to execute --
and return a function, which is the code block we have to run
in oder to produce the expected behavior.

Executing instructions
----------------------

CPU core, because of their design, are in a certain sence inherently slower
than the original ardware.
Emulating the behavior of a processor means
teller your own CPU to execute a certain set of instruction that
aim at reproducing what __one__ instruction of the
targeted hardware can do.
If Game Boy's emulater can run actually faster than original
harware is only because our processor are now a lot faster.
Where the original Game Boy CPU was doing near one million instructions
per second, today's computer do more than two billion instructions per seconds.

Even if today's computer are fast, try to keep emulated
functions simple, as simplicity is more likely to induce a short
nuber of instructions executed by your host CPU.
An implementation of an instruction will look at the values
given as argument, change the internal states of the vm
(the cpu's states and eventually the memory)
and return a description of the time this instruction should have
take if executed by the Game Boy's CPU.
To describe the time, we introduce the structure `Clock`.
We count the time in a unit which is a _clock cycle_.
In the Game Boy their is actually a small quartz crystal
oscillating at a frequency of 4.194304 MHz called the clock.
One of this oscillation is then called a _clock cycle_.
Notice that since an opcode can have an operand
following it in memory, like an number for an add instruction,
an instruction (opcode and it's operands) can actually
be more than one byte.
Though their is not direct use of this knowledge, we also
track this value for debuging.

``` {.haskell}
struct Clock {
    /// Length in byte of the last instruction
    m : u64,
    /// Duration in clock cycles
    t : u64,
}
```

Most of the instructions affect the _flag register_ `F`.
This register contains different bytes activated
or unactivated depending on the result of the last instruction.
Each of such bites are called flags.
They are used in conditionnal jump to know if a value is
greather than the other, if two values are equals, and so on.
Here is a table reasuming the different flags.

:Flag register `F`

+-------------+-----------------+---------------------+---------------+
| Bit 7 : Z   | Bit 6 : N       | Bit 5 : H           | Bit 4 : C     |
+:============+=================+:====================+:==============+
| Zero bit    | Negative bit    | Half Carry bit      | Carry bit     |
+-------------+-----------------+---------------------+---------------+
|             |                 |                     |               |
+-------------+-----------------+---------------------+---------------+
|Set to 0     |Set if the       |Set if a carry       |Set if a carry |
|if the result|operation use    |appear in the        |overflow the   |
|is null.     |negative numbers.|middle of the number.|register.      |
+-------------+-----------------+---------------------+---------------+

The description aren't precise and exact, but they summarise
the meaning of these flags.
You can find the details of how each operation affect the flag register in
annexe <TODO>.

Lets look at few example of simulated instructions.
The first example is the `ADD A, r` operation.

```
// Implement adding a register reg to the register A,
// and update the flag register F.
fn i_add_r(reg : u8, vm : &mut Vm) -> Clock {
    // Aliases for shorter expressions
    let a = vm.cpu.a;
    let b = reg;

    // Compute the sum
    let sum = vm.cpu.a + b;

    set_flag(vm, Flag::Z, sum == 0);
    set_flag(vm, Flag::N, false);
    set_flag(vm, Flag::H, (0x0F & a) + (0x0F & b) > 0xF);
    set_flag(vm, Flag::C, (b as u16) + (a as u16) > 0xFF);
	
    // Store the result in the register A
    vm.cpu.a = sum;

    Clock { m:1, t:4 }
}

// Set the specified flag to the value given
fn set_flag(vm : &mut Vm, flag : Flag, value : bool) {
    if value {
        vm.cpu.f |= 1 << flag as usize
    }
    else {
        vm.cpu.f &= !(1 << flag as usize)
    }
}

// Reset the flags of the Vm (set all flags to 0)
fn reset_flags(vm: &mut Vm) {
    vm.cpu.f = 0
}
```

Notice that settings the flags can be tricky,
especially the half carry flag `H`.

The second is the `JP addr` operation, which jump to
the address stored in the next two bytes of memory.

``` {.rust}
// Read the next two bytes and jump to the address
fn i_jp(vm : &mut Vm) -> Clock {
    vm.cpu.pc = read_program_word(vm.mmu);
    Clock { m:3, t:16 }
}
```

As you can see, the previous functions are generic in the sence
that they need to be specialised for specific registers.
For example, we would like to implement both `ADD A, B` and `ADD A, C`
as a specialisation of the previous functions.

Dispatching instructions
------------------------

Once we have implemented the behavior for one instruction, we have
to associate at each opcode the corresponding block of code.
This work is doone by the `dispatch` function.

Usually, in `C`, we would use an array indexed by the
different value that can take a byte (0 to 255) which alement are
pointer on fuction (namely the adresses of block of code).
Using the keyword `case` on a value of a byte in C would
be converted to an array of function pointer automatically by
the compiler, allowing to have a really fast condition branching
(instead of comparing the value of the byteode
through 256 different if block, we just read the function to
execute as a value in an
array which is way faster).
In `rust`, we can use the `match` keyword and expect
a similar optimisation.

instead of directly calling the right block of code,
we actually return this block of instruction. This allow
more flexibility in case you would alsolike to implement a
disassembler, or a debugguer in your emulator.
Since writing the CPU core is the part of emulator more propice
to expect bugs, adding a real-time debugguer --
a way to see which instruction are executed and
what are the current state of the CPU while running -- to your
implementation is a good way to help you discover bugs in your
code.

The return type of the dispatch function is a bit
particular, it is a `Box<Fn(&mut Vm) -> Clock>`.
This type allow us to take any function or closure
that take a mutable reference on a `Vm` and
produce a `Clock`.

``` {.rust}
fn dispatch(opcode : u8) -> Box<Fn(&mut Vm) -> Clock> {
    match opcode {
        // NOP
        0x00 => Box::new(|$vm : &mut Vm| i_nop(vm)),

        // ...
        
        // ADD A, r
        0x80 => Box::new(|$vm : &mut Vm| i_addr(vm.cpu.b, vm)],
        0x81 => Box::new(|$vm : &mut Vm| i_addr(vm.cpu.c, vm)],
        0x82 => Box::new(|$vm : &mut Vm| i_addr(vm.cpu.d, vm)],

        // ...

        // JUMP
        0xC3 => Box::new(|$vm : &mut Vm| i_jp(vm)],

        // ...
    }
}
```

# MBC


# Annex A
CPU's registers
# Annex B
CPU Opcode table 1
CPU Opcode table 2

Refs:

* Wikipedia https://en.wikipedia.org/wiki/Instruction_cycle#Decoding_the_instruction
* GBCPUMAN http://marc.rawer.de/Gameboy/Docs/GBCPUman.pdf
* PANDOCS http://bgb.bircd.org/pandocs.htm#lcdinterrupts
* How do I write an emulator http://www.atarihq.com/danb/files/emu_vol1.txt
